{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --user --upgrade tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbZBMfiwHBse",
        "outputId": "a5de009f-0116-4d8f-c3ad-9f25401e3af9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.23.5)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow[and-cuda]==2.14.*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zKdCIL3Vc9gj",
        "outputId": "edf8026a-e2fb-42a3-f0ac-95b2eb1fa936"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow[and-cuda]==2.14.*\n",
            "  Downloading tensorflow-2.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.9/489.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow[and-cuda]==2.14.*) (1.60.0)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.15,>=2.14.0 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.7.0.84 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_cudnn_cu11-8.7.0.84-py3-none-manylinux1_x86_64.whl (728.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m728.5/728.5 MB\u001b[0m \u001b[31m762.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.16.5 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_nccl_cu11-2.16.5-py3-none-manylinux1_x86_64.whl (210.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.3/210.3 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvcc-cu11==11.8.89 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading nvidia_cuda_nvcc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorrt==8.5.3.1 (from tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading tensorrt-8.5.3.1-cp310-none-manylinux_2_17_x86_64.whl (549.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.5/549.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow[and-cuda]==2.14.*) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (2.17.3)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow[and-cuda]==2.14.*) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvcc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, keras, nvidia-cusolver-cu11, nvidia-cudnn-cu11, tensorrt, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.1\n",
            "    Uninstalling tensorboard-2.15.1:\n",
            "      Successfully uninstalled tensorboard-2.15.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "Successfully installed google-auth-oauthlib-1.0.0 keras-2.14.0 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvcc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-8.7.0.84 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.16.5 tensorboard-2.14.1 tensorflow-2.14.1 tensorflow-estimator-2.14.0 tensorrt-8.5.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from keras import utils\n",
        "print(tf.__version__)\n",
        "\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb8t9TZ9HBvY",
        "outputId": "4c138a1b-2e4c-4dad-fa8a-aea1a0f64fe7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.1\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Количество классов изображений\n",
        "nb_classes = 10\n",
        "# Названия классов из набора данных CIFAR-10\n",
        "classes=['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']\n",
        "# разделение тренировочной и тестовой выборки\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "y_train10 = utils.to_categorical(y_train, nb_classes)\n",
        "y_test10 = utils.to_categorical(y_test, nb_classes)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'тренировочные примеры')\n",
        "print(x_test.shape[0], 'тестовые примеры')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhsXqG30JrYP",
        "outputId": "ad07704d-447e-4821-dba3-380283869f0d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 тренировочные примеры\n",
            "10000 тестовые примеры\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Загрузка предварительно обученной модели\n",
        "vgg19 = VGG19(include_top=False, weights ='imagenet', input_shape=(32, 32, 3), pooling=None)"
      ],
      "metadata": {
        "id": "8BUhF6I_HjdS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Фиксация всех слоев в базовой модели\n",
        "for layer in vgg19.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "aqwRy85HJB7s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Создание последовательной модели и добавление в неё VGG19\n",
        "base_model = Sequential()\n",
        "base_model.add(vgg19)"
      ],
      "metadata": {
        "id": "_9bULOyYJDFP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Компиляция модели к последующему обучению\n",
        "base_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='SGD',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "N4wsJVScH2H0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.add(BatchNormalization())\n",
        "base_model.add(Flatten()) # векторим вход\n",
        "base_model.add(Dense(256,activation='relu'))\n",
        "base_model.add(Dense(10,activation='softmax'))\n",
        "base_model.summary()\n",
        "print(base_model.layers[-1].input_shape)\n",
        "print(base_model.layers[-1].output_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVGvUGi8JUXw",
        "outputId": "92ce5ea8-a192-4a5f-f5c1-307485de0d4d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 1, 1, 512)         2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20160330 (76.91 MB)\n",
            "Trainable params: 134922 (527.04 KB)\n",
            "Non-trainable params: 20025408 (76.39 MB)\n",
            "_________________________________________________________________\n",
            "(None, 256)\n",
            "(None, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = base_model.fit(x_train, y_train10,\n",
        "              #batch_size=batch_size,\n",
        "              epochs=5,\n",
        "              validation_data=(x_test, y_test10),\n",
        "              shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjUTn_vZIDPz",
        "outputId": "a01a99db-c106-473d-dcd6-7db193d6b3de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 23s 13ms/step - loss: 1.4902 - accuracy: 0.4846 - val_loss: 1.3124 - val_accuracy: 0.5560\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.2595 - accuracy: 0.5620 - val_loss: 1.2387 - val_accuracy: 0.5828\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1931 - accuracy: 0.5832 - val_loss: 1.2026 - val_accuracy: 0.5917\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 27s 17ms/step - loss: 1.1505 - accuracy: 0.6001 - val_loss: 1.1821 - val_accuracy: 0.6006\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1167 - accuracy: 0.6115 - val_loss: 1.1692 - val_accuracy: 0.6033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model_accuracy = history.history['accuracy'][4]"
      ],
      "metadata": {
        "id": "vkz7YQQjIIjH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_model_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iURc8dsLxOi",
        "outputId": "cb5dea64-54e2-4eca-ce7a-3b68278aa12b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6114799976348877"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Прунинг"
      ],
      "metadata": {
        "id": "bj2vkWG8QsKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прунинг нейронной сети это метод сжатия модели, путем удаления части параметров."
      ],
      "metadata": {
        "id": "UF2YgxxGQuY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "end_step = np.ceil(1.0 * x_train.shape[0] / nb_classes).astype(np.int32) * EPOCHS\n",
        "\n",
        "pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(\n",
        "                        initial_sparsity=0.0, final_sparsity=0.5,\n",
        "                        begin_step=0, end_step=end_step, frequency=100)\n",
        "\n",
        "#layer.input_shape[-1]\n",
        "pruned_model = tf.keras.Sequential()\n",
        "for layer in base_model.layers:\n",
        "    if(re.match(r\"conv_pw_\\d+$\", layer.name)):\n",
        "         pruned_model.add(tfmot.sparsity.prune_low_magnitude(\n",
        "            layer,\n",
        "            pruning_schedule,\n",
        "            block_size=(1,1)\n",
        "         ))\n",
        "    else:\n",
        "        pruned_model.add(layer)\n",
        "\n",
        "pruned_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='SGD',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Q53kq3GHOxsT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_prun = pruned_model.fit(x_train, y_train10,\n",
        "              #batch_size=batch_size,\n",
        "              epochs=5,\n",
        "              validation_data=(x_test, y_test10),\n",
        "              shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twY-LgTeQPGq",
        "outputId": "28842657-3291-460e-94ce-c1f73a1fb93e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 24s 15ms/step - loss: 1.0915 - accuracy: 0.6196 - val_loss: 1.1595 - val_accuracy: 0.6093\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 23s 14ms/step - loss: 1.0691 - accuracy: 0.6286 - val_loss: 1.1502 - val_accuracy: 0.6127\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0479 - accuracy: 0.6355 - val_loss: 1.1433 - val_accuracy: 0.6089\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 1.0312 - accuracy: 0.6381 - val_loss: 1.1406 - val_accuracy: 0.6149\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 23s 14ms/step - loss: 1.0158 - accuracy: 0.6461 - val_loss: 1.1358 - val_accuracy: 0.6163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_accuracy = history_prun.history['accuracy'][4]"
      ],
      "metadata": {
        "id": "C3YdqB6-QZ-8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PA7pPZc9Q7zi",
        "outputId": "a8ff8dab-9330-4306-ba5d-0e7d8c7b3fcb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.646120011806488"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Квантизация"
      ],
      "metadata": {
        "id": "O_rkLvsmQ6QP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Все операции проводятся в целочисленных значениях. Чаще всего это накладывается на слой или на какую-то часть сети. Ряд слоёв работает в int8, благодаря чему он потребляет очень мало вычислений и памяти, последний слой, float32."
      ],
      "metadata": {
        "id": "_qbYkJ2sRAOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Создание последовательной модели и добавление в неё VGG19\n",
        "quant_model = Sequential()\n",
        "quant_model.add(vgg19)"
      ],
      "metadata": {
        "id": "z29iGfx2WyMn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='SGD',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ISGJqOWMV991"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_model.add(BatchNormalization())\n",
        "quant_model.add(Flatten()) # векторим вход\n",
        "quant_model.add(Dense(256,activation='relu'))\n",
        "quant_model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "LCZtDqOtXF8G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_quant = quant_model.fit(x_train, y_train10,\n",
        "              #batch_size=batch_size,\n",
        "              epochs=5,\n",
        "              validation_data=(x_test, y_test10),\n",
        "              shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNkpjHyWWGmF",
        "outputId": "fcb1243d-244c-43cc-8523-7e237aa7a596"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 25s 15ms/step - loss: 1.5075 - accuracy: 0.4781 - val_loss: 1.3297 - val_accuracy: 0.5538\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 23s 14ms/step - loss: 1.2600 - accuracy: 0.5630 - val_loss: 1.2474 - val_accuracy: 0.5706\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 1.1925 - accuracy: 0.5841 - val_loss: 1.2110 - val_accuracy: 0.5850\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 21s 13ms/step - loss: 1.1568 - accuracy: 0.5962 - val_loss: 1.1885 - val_accuracy: 0.5912\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 22s 14ms/step - loss: 1.1201 - accuracy: 0.6091 - val_loss: 1.1702 - val_accuracy: 0.5987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model_accuracy = history_quant.history['accuracy'][4]"
      ],
      "metadata": {
        "id": "Rw7_W7gKSjuN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_model_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IclbwdG6X2IS",
        "outputId": "70265d44-29d9-44a5-d8ee-97c89996a056"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6090599894523621"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кластеринг"
      ],
      "metadata": {
        "id": "u0zXct63Z13G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_weights = tfmot.clustering.keras.cluster_weights"
      ],
      "metadata": {
        "id": "w_TCzSdinQlY"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itNDCt0hrXIP",
        "outputId": "1676964e-38af-4d4f-d506-ce77221c30b2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function tensorflow_model_optimization.python.core.clustering.keras.cluster.cluster_weights(to_cluster, number_of_clusters, cluster_centroids_init=<CentroidInitialization.KMEANS_PLUS_PLUS: 'CentroidInitialization.KMEANS_PLUS_PLUS'>, **kwargs)>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clustering_params = {\n",
        "    'number_of_clusters': 32,\n",
        "    'cluster_centroids_init': tfmot.clustering.keras.CentroidInitialization.LINEAR\n",
        "}"
      ],
      "metadata": {
        "id": "L9pP7XMLtuAl"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = base_model.weights[0][0]"
      ],
      "metadata": {
        "id": "wfxAVzkuueWu"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustered_model = cluster_weights(w, **clustering_params)"
      ],
      "metadata": {
        "id": "2phiXdAKuSFr"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Конвертируем модель в TensorRT для инференса"
      ],
      "metadata": {
        "id": "_3SFBXxSfl9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model in the saved_model format\n",
        "SAVED_MODEL_DIR=\"./content/my_model/native_saved_model\"\n",
        "base_model.save(SAVED_MODEL_DIR)"
      ],
      "metadata": {
        "id": "ktZ2PuGMaXAr"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
        "\n",
        "# Instantiate the TF-TRT converter\n",
        "converter = trt.TrtGraphConverterV2(\n",
        "   input_saved_model_dir=SAVED_MODEL_DIR,\n",
        "   precision_mode=trt.TrtPrecisionMode.FP32\n",
        ")\n",
        "\n",
        "# Convert the model into TRT compatible segments\n",
        "trt_func = converter.convert()\n",
        "converter.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RP0PQ1YmcrX6",
        "outputId": "9d7c5072-257e-4345-d471-78f5d6323f0b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRTEngineOP Name                 Device        # Nodes # Inputs      # Outputs     Input DTypes       Output Dtypes      Input Shapes       Output Shapes     \n",
            "================================================================================================================================================================\n",
            "TRTEngineOp_000_000              device:GPU:0  102     1             1             ['float32']        ['float32']        [[-1, 32, 32, 3]]  [[-1, 10]]        \n",
            "\n",
            "\t- BiasAdd: 18x\n",
            "\t- Const: 41x\n",
            "\t- Conv2D: 16x\n",
            "\t- FusedBatchNormV3: 1x\n",
            "\t- MatMul: 2x\n",
            "\t- MaxPool: 5x\n",
            "\t- Relu: 17x\n",
            "\t- Reshape: 1x\n",
            "\t- Softmax: 1x\n",
            "\n",
            "================================================================================================================================================================\n",
            "[*] Total number of TensorRT engines: 1\n",
            "[*] % of OPs Converted: 98.08% [102/104]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the converted model for future use\n",
        "OUTPUT_SAVED_MODEL_DIR=\"../content/my_model/tftrt_saved_model\"\n",
        "converter.save(output_saved_model_dir=OUTPUT_SAVED_MODEL_DIR)"
      ],
      "metadata": {
        "id": "ZWNTi-cJilwy"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cгенерировать датасет из векторов (размер не менее 1000 векторов)"
      ],
      "metadata": {
        "id": "5TcPNbeD1K3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормализация\n",
        "train_images = (x_train / 255) * 2 - 1\n",
        "test_images = (x_test / 255) * 2 - 1\n",
        "\n",
        "# Векторизация\n",
        "train_images = train_images.reshape((-1, 1024))\n",
        "test_images = test_images.reshape((-1, 1024))"
      ],
      "metadata": {
        "id": "fvJE59htux3X"
      },
      "execution_count": 96,
      "outputs": []
    }
  ]
}